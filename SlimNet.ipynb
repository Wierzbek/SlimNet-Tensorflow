{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import AveragePooling2D\n",
    "from tensorflow.keras.layers import MaxPool2D\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import concatenate\n",
    "from tensorflow.keras.layers import SeparableConv2D\n",
    "from tensorflow.keras.layers import Add\n",
    "from tensorflow.keras.layers import ZeroPadding2D\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Flatten\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolution with Batch Norm & ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBNReLU(Model):   \n",
    "    def __init__(self, filters, kernel_size, strides=1):\n",
    "        super().__init__()\n",
    "        if(kernel_size == 1):\n",
    "            padding = 0\n",
    "        else:\n",
    "            padding = 1        \n",
    "        # Conv2D\n",
    "        self.addPadding = ZeroPadding2D(padding)\n",
    "        self.Conv = Conv2D(filters, kernel_size, strides)\n",
    "        # Batch Normalization\n",
    "        self.BN = BatchNormalization()\n",
    "        # Activation Function\n",
    "        self.AF = Activation(\"relu\")\n",
    "    def call(self, x):\n",
    "        x = self.addPadding(x)\n",
    "        x = self.Conv(x)\n",
    "        x = self.BN(x)\n",
    "        return self.AF(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Depthwise Separable Convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "class depthwise_separable(Model):\n",
    "    def __init__(self, filters, kernel_size):\n",
    "        super().__init__()\n",
    "        #add padding\n",
    "        self.addPadding = ZeroPadding2D(padding=1)\n",
    "        # Depthwise Convolution 3x3\n",
    "        self.DWSeparableConv = SeparableConv2D(filters, kernel_size)\n",
    "        # Batch Normalization\n",
    "        self.BN = BatchNormalization()\n",
    "        # Activation Function\n",
    "        self.AF = Activation(\"relu\")\n",
    "    def call(self, x):\n",
    "        x = self.addPadding(x)\n",
    "        x = self.DWSeparableConv(x)\n",
    "        x = self.BN(x)\n",
    "        return self.AF(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separable Squeeze-Expand Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class SSEModel(Model):\n",
    "    def __init__(self, squeeze, expand):\n",
    "        super().__init__()\n",
    "        #squeeze\n",
    "        self.pointwise1 = ConvBNReLU(squeeze, 1)\n",
    "        #expand\n",
    "        self.pointwise2 = ConvBNReLU(expand, 1)\n",
    "        self.depthwise = depthwise_separable(expand, 3)\n",
    "    def call(self, x):\n",
    "        x = self.pointwise1(x)\n",
    "        y = self.pointwise2(x)\n",
    "        z = self.depthwise(x)\n",
    "        return tf.keras.layers.Concatenate()([y, z])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Slim Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class SlimModule(Model):\n",
    "    def __init__(self, squeeze, expand, dws, filtersNo):\n",
    "        super().__init__()\n",
    "        #SSE block 1\n",
    "        self.SSE1 = SSEModel(squeeze, expand)\n",
    "        #skip connection\n",
    "        self.SkipConnection = 0\n",
    "        #Dense\n",
    "        self.dns = Dense(filtersNo, activation='relu')\n",
    "        #SSE block 2\n",
    "        self.SSE2 = SSEModel(squeeze, expand)\n",
    "        \n",
    "        #depthwise separable conv missing?\n",
    "        self.depthwise = depthwise_separable(dws, 3)\n",
    "    def call(self, x):\n",
    "        s1 = self.SSE1(x)\n",
    "        s1 = self.dns(s1)\n",
    "        SkipConnection = Add()([x, s1])\n",
    "        s2 = self.SSE2(SkipConnection)\n",
    "        return self.depthwise(s2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SlimNet - CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_56\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_931 (Conv2D)          (None, 128, 128, 96)      14208     \n",
      "_________________________________________________________________\n",
      "activation_1435 (Activation) (None, 128, 128, 96)      0         \n",
      "_________________________________________________________________\n",
      "slim_module_168 (SlimModule) (None, 128, 128, 48)      28816     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_168 (MaxPoolin (None, 63, 63, 48)        0         \n",
      "_________________________________________________________________\n",
      "slim_module_169 (SlimModule) (None, 63, 63, 96)        62608     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_169 (MaxPoolin (None, 31, 31, 96)        0         \n",
      "_________________________________________________________________\n",
      "slim_module_170 (SlimModule) (None, 31, 31, 144)       147696    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_170 (MaxPoolin (None, 15, 15, 144)       0         \n",
      "_________________________________________________________________\n",
      "slim_module_171 (SlimModule) (None, 15, 15, 192)       268624    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_171 (MaxPoolin (None, 7, 7, 192)         0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_41  (None, 192)               0         \n",
      "_________________________________________________________________\n",
      "dense_212 (Dense)            (None, 1)                 193       \n",
      "=================================================================\n",
      "Total params: 522,145\n",
      "Trainable params: 515,425\n",
      "Non-trainable params: 6,720\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "slim = Sequential()\n",
    "slim.add(Input(shape=(256, 256, 3)))\n",
    "slim.add(Conv2D(96, (7, 7), (2, 2), padding='same'))\n",
    "slim.add(Activation('relu'))\n",
    "\n",
    "#Slim module 1\n",
    "slim.add(SlimModule(16, 64, 48, 96))\n",
    "slim.add(MaxPool2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "\n",
    "#Slim module 2\n",
    "slim.add(SlimModule(32, 128, 96, 48))\n",
    "slim.add(MaxPool2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "\n",
    "#Slim module 3\n",
    "slim.add(SlimModule(48, 192, 144, 96))\n",
    "slim.add(MaxPool2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "\n",
    "#Slim module 4\n",
    "slim.add(SlimModule(64, 256, 192, 144))\n",
    "slim.add(MaxPool2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "\n",
    "slim.add(GlobalAveragePooling2D())\n",
    "\n",
    "slim.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(\n",
    "    learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False,\n",
    "    name='Adam')\n",
    "\n",
    "slim.compile(loss = 'binary_crossentropy',\n",
    "              optimizer = 'adam',\n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "print(slim.summary())\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check for Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 141819 images belonging to 1 classes.\n",
      "Found 40519 images belonging to 1 classes.\n",
      "Found 20261 images belonging to 1 classes.\n",
      "Batch shape=(32, 256, 256, 3), min=0.000, max=255.000\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "# create generator\n",
    "datagen = ImageDataGenerator()\n",
    "# prepare an iterators for each dataset\n",
    "train_it = datagen.flow_from_directory('output/train/', class_mode='binary')\n",
    "val_it = datagen.flow_from_directory('output/val/', class_mode='binary')\n",
    "test_it = datagen.flow_from_directory('output/test/', class_mode='binary')\n",
    "# confirm the iterator works\n",
    "batchX, batchy = train_it.next()\n",
    "print('Batch shape=%s, min=%.3f, max=%.3f' % (batchX.shape, batchX.min(), batchX.max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train & Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 31/312 [=>............................] - ETA: 39:36 - loss: 0.1366 - accuracy: 0.9878"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"output/savedModel\",\n",
    "                             monitor=\"val_loss\",\n",
    "                             mode=\"min\",\n",
    "                             save_best_only = True,\n",
    "                             verbose=1)\n",
    "\n",
    "earlystop = EarlyStopping(monitor = 'val_loss', \n",
    "                          min_delta = 0, \n",
    "                          patience = 3,\n",
    "                          verbose = 1)\n",
    "\n",
    "# we put our call backs into a callback list\n",
    "callbacks = [earlystop, checkpoint]\n",
    "\n",
    "\n",
    "nb_train_samples = 20000\n",
    "nb_validation_samples = 4000\n",
    "epochs = 1\n",
    "batch_size = 64\n",
    " \n",
    "history = slim.fit(\n",
    "    train_it,\n",
    "    steps_per_epoch = nb_train_samples // batch_size,\n",
    "    epochs = epochs,\n",
    "    callbacks = callbacks,\n",
    "    validation_data = val_it,\n",
    "    validation_steps = nb_validation_samples // batch_size)\n",
    "\n",
    "slim.save(\"SlimNet_Model_opt-adam.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
